# <이유한님> 캐글 스터디 커리큘럼  

## 목차
1. Binary classification : Tabular data  
[1.1 level. Titanic: Machine Learning from Disaster](#titanic-machine-learning-from-disaster)  
[1.2 level. Porto Seguro’s Safe Driver Prediction](#porto-seguro-safe-driver-prediction)  
[1.3 level. Home Credit Default Risk](#home-credit-default-risk)  
  
2. Multi-class classification : Tabular data  
[2.1 level. Costa Rican Household Poverty Level Prediction](#costa-rican-household-poverty-level-prediction)  
3. Binary classification : Image classification  
[3.1 level. Statoil/C-CORE Iceberg Classifier Challenge](#statoil-c-core-iceberg-classifier-challenge)  
4. Multi-class classification : Image classification  
[4.1 level. TensorFlow Speech Recognition Challenge](#tensorflow-speech-recognition-challenge)  
5. Regression : Tabular data  
[5.1 level. New York City Taxi Trip Duration](#new-york-city-taxi-trip-duration)  
[5.2 level. Zillow Prize: Zillow’s Home Value Prediction (Zestimate)](#zillow-prize-zillow-home-value-prediction-zestimate)  
6. Object segmentation : Deep learning  
[6.1 level. 2018 Data Science Bowl](#2018-data-science-bowl)  
7. Natural language processing : classification, regression  
[7.1 level. Spooky Author Identification](#spooky-author-identification)  
[7.2 level. Mercari Price Suggestion Challenge](#mercari-price-suggestion-challenge)  
[7.3 level. Toxic Comment Classification Challenge](#toxic-comment-classification-challenge)  
8. Other dataset : anomaly detection, visualization  
[8.1 level. Credit Card Fraud Detection](#credit-card-fraud-detection)  
[8.2 level. Kaggle Machine Learning & Data Science Survey 2017](#kaggle-machine-learning-and-data-science-survey-2017)  




## 1.Binary classification : Tabular data

### Titanic Machine Learning from Disaster

[타이타닉 튜토리얼 - Exploratory data analysis, visualization, machine learning](https://kaggle-kr.tistory.com/17?category=868316)

<학습일시>
년 | 월 | 일
---|---|---
2020년 | 12월 | 7일
2020년 | 12월 | 8일
2020년 | 12월 | 10일

[EDA To Prediction(DieTanic)](https://www.kaggle.com/ash316/eda-to-prediction-dietanic)

<학습일시>
년 | 월 | 일
---|---|---
2020년 | 12월 | 11일
2021년 | 01월 | 02일
2021년 | 01월 | 05일

[Titanic Top 4% with ensemble modeling](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling)

<학습일시>
년 | 월 | 일
---|---|---
2020년 | 12월 | 12일
2020년 | 12월 | 16일
2020년 | 12월 | 28일

[Introduction to Ensembling/Stacking in Python](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python)

<학습일시>
년 | 월 | 일
---|---|---
2021년 | 01월 | 06일
2021년 | 01월 | 07일
2021년 | 01월 | 08일

### Porto Seguro Safe Driver Prediction

[Data Preparation & ExplorationPorto](https://www.kaggle.com/bertcarremans/data-preparation-exploration)

<학습일시>
년 | 월 | 일
---|---|---
2021년 | 01월 | 12일
2021년 | 01월 | 13일
년 | 월 | 일

[Interactive Porto Insights - A Plot.ly Tutorial](https://www.kaggle.com/arthurtok/interactive-porto-insights-a-plot-ly-tutorial)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[XGBoost CV (LB .284)](https://www.kaggle.com/aharless/xgboost-cv-lb-284)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Seguro Exploratory Analysis and Prediction](https://www.kaggle.com/gpreda/porto-seguro-exploratory-analysis-and-prediction)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

### Home Credit Default Risk

[Introduction: Home Credit Default Risk Competition](https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Introduction to Manual Feature Engineering](https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Stacking Test-Sklearn, XGBoost, CatBoost, LightGBM](https://www.kaggle.com/eliotbarr/stacking-test-sklearn-xgboost-catboost-lightgbm)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[LightGBM 7th place solution](https://www.kaggle.com/jsaguiar/lightgbm-7th-place-solution)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

## 2.Multi-class classification : Tabular data

### Costa Rican Household Poverty Level Prediction

[A Complete Introduction and Walkthrough](https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[3250feats->532 feats using shap[LB: 0.436]](https://www.kaggle.com/youhanlee/3250feats-532-feats-using-shap-lb-0-436)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[XGBoost](https://www.kaggle.com/skooch/xgboost)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

## 3.Binary classification : Image classification

### Statoil C CORE Iceberg Classifier Challenge

[Keras Model for Beginners (0.210 on LB)+EDA+R&D](https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Transfer Learning with VGG-16 CNN+AUG LB 0.1712](https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Submarineering.EVEN BETTER PUBLIC SCORE until now.](https://www.kaggle.com/submarineering/submarineering-even-better-public-score-until-now)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Keras+TF LB 0.18](https://www.kaggle.com/wvadim/keras-tf-lb-0-18)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

## 4.Multi-class classification : Image classification

### TensorFlow Speech Recognition Challenge

[Speech representation and data exploration](https://www.kaggle.com/davids1992/speech-representation-and-data-exploration)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Light-Weight CNN LB 0.74](https://www.kaggle.com/alphasis/light-weight-cnn-lb-0-74)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[WavCeption V1: a 1-D Inception approach (LB 0.76)](https://www.kaggle.com/ivallesp/wavception-v1-a-1-d-inception-approach-lb-0-76)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

## 5.Regression : Tabular data

### New York City Taxi Trip Duration

[Dynamics of New York city - Animation](https://www.kaggle.com/drgilermo/dynamics-of-new-york-city-animation)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[EDA + Baseline Model](https://www.kaggle.com/aiswaryaramachandran/eda-baseline-model-0-40-rmse)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Beat the benchmark!](https://www.kaggle.com/danijelk/beat-the-benchmark)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

### Zillow Prize Zillow Home Value Prediction Zestimate

[Simple Exploration Notebook - Zillow Prize](https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Simple XGBoost Starter (~0.0655)](https://www.kaggle.com/anokas/simple-xgboost-starter-0-0655)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Zillow EDA On Missing Values & Multicollinearity](https://www.kaggle.com/viveksrinivasan/zillow-eda-on-missing-values-multicollinearity)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[XGBoost, LightGBM, and OLS and NN](https://www.kaggle.com/aharless/xgboost-lightgbm-and-ols-and-nn)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

## 6.Object segmentation : Deep learning

### 2018 Data Science Bowl

[Teaching notebook for total imaging newbies](https://www.kaggle.com/stkbailey/teaching-notebook-for-total-imaging-newbies)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Keras U-Net starter - LB 0.277](https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Nuclei Overview to Submission](https://www.kaggle.com/kmader/nuclei-overview-to-submission)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

## 7.Natural language processing : classification, regression

### Spooky Author Identification

[Spooky NLP and Topic Modelling tutorial](https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Approaching (Almost) Any NLP Problem on Kaggle](https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Simple Feature Engg Notebook - Spooky Author](https://www.kaggle.com/sudalairajkumar/simple-feature-engg-notebook-spooky-author)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

### Mercari Price Suggestion Challenge

[Mercari Interactive EDA + Topic Modelling](https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[A simple nn solution with Keras (~0.48611 PL)](https://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Ridge (LB 0.41943)](https://www.kaggle.com/rumbok/ridge-lb-0-41944)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[LGB and FM (18th Place - 0.40604)](https://www.kaggle.com/peterhurford/lgb-and-fm-18th-place-0-40604)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

### Toxic Comment Classification Challenge

[(For Beginners) Tackling Toxic Using Keras](https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Stop the S@#$ - Toxic Comments EDA](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Logistic regression with words and char n-grams](https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Classifying multi-label comments (0.9741 lb)](https://www.kaggle.com/rhodiumbeng/classifying-multi-label-comments-0-9741-lb)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

## 8.Other dataset : anomaly detection, visualization

### Credit Card Fraud Detection

[In depth skewed data classif. (93% recall acc now)](https://www.kaggle.com/joparga3/in-depth-skewed-data-classif-93-recall-acc-now)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Anomaly Detection - Credit Card Fraud Analysis](https://www.kaggle.com/pavansanagapati/anomaly-detection-credit-card-fraud-analysis)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[Semi-Supervised Anomaly Detection Survey](https://www.kaggle.com/matheusfacure/semi-supervised-anomaly-detection-survey)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

### Kaggle Machine Learning and Data Science Survey 2017

[Novice to Grandmaster](https://www.kaggle.com/ash316/novice-to-grandmaster)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[What do Kagglers say about Data Science ?](https://www.kaggle.com/mhajabri/what-do-kagglers-say-about-data-science)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

[PLOTLY TUTORIAL - 1](https://www.kaggle.com/hakkisimsek/plotly-tutorial-1)

<학습일시>
년 | 월 | 일
---|---|---
년 | 월 | 일
년 | 월 | 일
년 | 월 | 일

